[[["093cb33c-7a89-4856-a0ef-d30f587cebaa",{"pageContent":"1. Introduction \n \n                          Compiler  is  a  translator  program  that  translates  a  program  written  in \n(HLL)  the  source  program  and  translates  it  into  an  equivalent  program  in  (MLL)  the \ntarget  program.  As  an  important  part of  a  compiler  is  error showing  to the  programmer. \nExecuting  a  program  written  in  HLL  programming  language  is  basically  of  two  parts. \nThe  source  program  must  first  be  compiled  translated  into  an  object  program.  Then  the \nresults object program is loaded into a memory executed. \n \nWho developed the first compiler for a computer programming language? \nThe  first  compiler  was  written  by Grace  Hopper, in  1952,  for the  A-0  System  language. \nThe term compiler was coined by Hopper. The A-0 functioned more as a loader or linker \nthan the  modern notion of a compiler. The FORTRAN team  led by John Backus at IBM","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.718Z","chunkIndex":0,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_0_1763525937718","subject":"cd"}}],["732c9f95-4b1b-4e0d-ab17-7aa96aa76eca",{"pageContent":"than the  modern notion of a compiler. The FORTRAN team  led by John Backus at IBM \nis generally credited as having introduced the first complete compiler in 1957. \n \nLanguage Processing System \n \n                 Source program  \n                           \n                                                                       \nExpands macros \n   \n \n                                       Modified source program \n \n \n \n \n                                      Target assembly program \n \n \nPreprocessor  \nCompiler \nAssembler","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":1,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_1_1763525937719","subject":"cd"}}],["c67c8062-bf50-4342-860f-c077c4610dc4",{"pageContent":"Relocatable machine code \n \n                                                                                                            \nLibrary files,  \n                  Relocatable object \nfiles \n \n \nTarget machine code \n \nPre-processor, Assembler, Loader and linker are also known as cousins of compiler. \nCompilers and Interpreters \n \n          Compilers generate machine code, whereas interpreters interpret intermediate code \nInterpreters are easier to write and can provide better error messages (symbol table is still \navailable)  Interpreters  are  at  least  5  times  slower  than  machine  code  generated  by \ncompilers Interpreters also require  much  more  memory than  machine code generated by \ncompilers Examples: Perl, Python, Unix Shell, Java, BASIC, LISP. \n \nThe Structure of a compiler \n \nA  compiler  is  a  huge  program  that  can  consists  of  10,000  to  1,000,000  lines  of  code.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":2,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_2_1763525937719","subject":"cd"}}],["6b541d03-96ce-4323-b239-b957238112d7",{"pageContent":"The Structure of a compiler \n \nA  compiler  is  a  huge  program  that  can  consists  of  10,000  to  1,000,000  lines  of  code. \nSince  compiler  is  a  huge  program  it  is  difficult  to  understand  the  entire  compilation \nprocess. So the process  is divided  into number of modules called as PHASES. There are \ntwo major phases of compiler. \n \n  \n \n \n \n \nAnalysis of the source program \nSynthesis of a machine-language program \nThe structure of compiler consists of two parts: \nLinker/Loader \nCompiler \nAnalysis Synthesis","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":3,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_3_1763525937719","subject":"cd"}}],["705614a0-64b2-4ecb-a0bc-07c162913aac",{"pageContent":"Analysis part \n•  Analysis  part  breaks  the  source  program  into  constituent  pieces  and  imposes  a \ngrammatical structure on them which further uses this structure to create an intermediate \nrepresentation of the source program. \n• It is also termed as front end of compiler. \n• Information about the source program is collected and stored in a data structure called \nsymbol table. \n                       \nSynthesis part \n• Synthesis part takes the intermediate representation as input and transforms it to the \ntarget program. \n• It is also termed as back end of compiler. \n                           \nThe  design  of  compiler  can  be  decomposed  into several  phases,  each  of  which  converts \none form of source program into another.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":4,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_4_1763525937719","subject":"cd"}}],["ce564e97-0e9a-4bd5-953a-cc13030e597f",{"pageContent":"Fig 1.1 Structure of Compiler \nThe phases of compiler are as follows: \n1. Lexical analysis \n2. Syntax analysis \n3. Semantic analysis \n4. Intermediate code generation \n5. Code optimization \n6. Code generation \nAll of the aforementioned phases involve the following tasks: \n• Symbol table management.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":5,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_5_1763525937719","subject":"cd"}}],["12892a69-5667-4a8a-b4d0-fc3d908c32a3",{"pageContent":"• Error handling. \n \nLexical Analysis \n• Lexical analysis is the first phase of compiler which is also termed as scanning. \n• Source program is scanned to read the stream of characters and those characters are \ngrouped to form a sequence called lexemes which produces token as output. \n• Token: Token  is  a  sequence  of  characters  that  represent  lexical  unit,  which  matches \nwith the pattern, such as keywords, operators, identifiers etc. \n• Lexeme: Lexeme is instance of a token i.e., group of characters forming a token. , \n• Pattern: Pattern describes the rule that the  lexemes of a token takes. It is the  structure \nthat must be matched by strings. \n• Once a token is generated the corresponding entry is made in the symbol table. \nInput: stream of characters \nOutput: Token \nToken Template: <token-name, attribute-value> \n(eg.) c=a+b*5; \n \n \n                                                 Lexemes and tokens \n  \nLexemes Tokens \nc identifier \n= assignment symbol \na identifier","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":6,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_6_1763525937719","subject":"cd"}}],["1635e15f-1f60-4d1f-a2d7-3c04901c734d",{"pageContent":"Lexemes and tokens \n  \nLexemes Tokens \nc identifier \n= assignment symbol \na identifier \n+ + (addition symbol)","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":7,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_7_1763525937719","subject":"cd"}}],["e698b6f2-d56f-4d13-8c21-357e699cd3d3",{"pageContent":"b identifier \n* * (multiplication symbol) \n5 5 (number) \n Hence, <id, 1><=>< id, 2>< +><id, 3 >< * >< 5> \nSyntax Analysis \n• Syntax analysis is the second phase of compiler which is also called as parsing. \n• Parser converts the tokens produced by lexical analyzer  into  a  tree  like  representation \ncalled parse tree. \n• A parse tree describes the syntactic structure of the input. \n               \n•  Syntax  tree  is  a  compressed  representation  of  the  parse  tree  in  which  the  operators \nappear as interior nodes and the operands of the operator are the children of the node for \nthat operator. \nInput: Tokens \nOutput: Syntax tree","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":8,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_8_1763525937719","subject":"cd"}}],["e2f6cf92-47e5-4333-83ea-8ca41a3d48f7",{"pageContent":"Semantic Analysis \n• Semantic analysis is the third phase of compiler. \n• It checks for the semantic consistency. \n• Type information is gathered and stored in symbol table or in syntax tree. \n• Performs type checking. \n                 \nIntermediate Code Generation \n•  Intermediate  code  generation  produces  intermediate  representations  for  the  source \nprogram which are of the following forms: \n     o Postfix notation \n     o Three address code","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.719Z","chunkIndex":9,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_9_1763525937719","subject":"cd"}}],["060883cd-9f05-4a36-8f44-d333144a1dea",{"pageContent":"o Syntax tree \nMost commonly used form is the three address code. \n        t\n1\n = inttofloat (5) \n        t\n2\n = id\n3\n* tl \n        t\n3\n = id\n2\n + t\n2\n \n        id\n1\n = t\n3\n \nProperties of intermediate code \n • It should be easy to produce. \n• It should be easy to translate into target program. \nCode Optimization \n• Code  optimization  phase  gets  the  intermediate  code  as  input  and  produces  optimized \nintermediate code as output. \n• It results in faster running machine code. \n• It can be done by reducing the number of lines of code for a program. \n• This phase reduces the redundant code  and  attempts  to  improve  the  intermediate  code \nso that faster-running machine code will result. \n• During the code optimization, the result of the program is not affected. \n• To improve the code generation, the optimization involves \n       o Deduction and removal of dead code (unreachable code). \n       o Calculation of constants in expressions and terms.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":10,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_10_1763525937720","subject":"cd"}}],["0e814c06-739f-4c4e-b00a-c0e07df60eb7",{"pageContent":"o Deduction and removal of dead code (unreachable code). \n       o Calculation of constants in expressions and terms. \n       o Collapsing of repeated expression into temporary string. \n       o Loop unrolling. \n       o Moving code outside the loop. \n       o Removal of unwanted temporary variables. \n                   t\n1\n = id\n3\n* 5.0 \n                   id\n1\n = id\n2\n + t\n1\n \nCode Generation","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":11,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_11_1763525937720","subject":"cd"}}],["7e662148-b79b-47b7-bc41-c1ec5b2ab6e0",{"pageContent":"• Code generation is the final phase of a compiler. \n• It gets input from code optimization phase and  produces the target code or object code \nas result. \n•  Intermediate  instructions  are  translated  into  a sequence  of  machine  instructions  that \nperform the same task. \n• The code generation involves \n     o Allocation of register and memory. \n     o Generation of correct references. \n     o Generation of correct data types. \n     o Generation of missing code. \n                LDF R\n2\n, id\n3\n \n                MULF R\n2\n, # 5.0 \n                LDF R\n1\n, id\n2\n \n                ADDF R\n1\n, R\n2\n \n                STF id\n1\n, R\n1\n \n \n Symbol Table Management \n • Symbol table is used to store all the information about identifiers used in the program. \n• It is a data structure containing a record for each identifier, with fields for the attributes \nof the identifier. \n• It allows finding the record for each identifier quickly and to store or retrieve data from \nthat record.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":12,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_12_1763525937720","subject":"cd"}}],["f84bceb2-a27f-4222-94b4-1e2cbb86cea8",{"pageContent":"of the identifier. \n• It allows finding the record for each identifier quickly and to store or retrieve data from \nthat record. \n• Whenever an identifier is detected in any of the phases, it is stored in the symbol table. \nExample \n int a, b; float c; char z;     \nSymbol name Type Address \na Int 1000","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":13,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_13_1763525937720","subject":"cd"}}],["4f1108ce-54ab-40e5-a73a-30814498b58c",{"pageContent":"b Int 1002 \nc Float 1004 \nz char 1008 \nExample \nextern double test (double x); \n   double sample (int count) \n{ \n   double sum= 0.0; \n     for (int i = 1; i < = count; i++) \n       sum+= test((double) i); \n       return sum; \n   } \n Symbol name \nType Scope \ntest function, double extern \nx double function parameter \nsample function, double global \ncount int function parameter \nsum double block local \ni int for-loop statement \n   \n \n\n \n \n                             \n \nError Handling","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":14,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_14_1763525937720","subject":"cd"}}],["71ef6205-fcd8-43b6-85ea-145777e3cfb0",{"pageContent":"Error Handling \n\n \n \n• Each phase can encounter errors. After detecting an error, a phase must handle the error \nso that compilation can proceed. \n• In lexical analysis, errors occur in separation of tokens. \n• In syntax analysis, errors occur during construction of syntax tree. \n• In semantic analysis, errors may occur at the following cases: \n(i)  When  the  compiler  detects  constructs  that  have  right  syntactic  structure  but  no \nmeaning \n(ii) During type conversion. \n• In code optimization, errors occur when the result is affected by the optimization. In \ncode generation, it shows error when code is missing etc. \nFigure  illustrates  the  translation  of  source  code  through  each  phase,  considering  the \nstatement \n    c =a+ b * 5.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":15,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_15_1763525937720","subject":"cd"}}],["8d421b0b-b444-48ba-8a80-68b0c31fdead",{"pageContent":"Lexical Analysis \nLexical analysis is the process of converting a sequence of characters from \nsource program into a sequence of tokens. \nA program which performs lexical analysis is termed as a lexical analyzer \n(lexer), tokenizer or scanner. \nLexical analysis consists of two stages of processing which are as follows: \n• Scanning \n• Tokenization \nToken, Pattern and Lexeme \nToken \nToken is a valid sequence of characters which are given by lexeme. In a \nprogramming language, \n• keywords, \n• constant, \n• identifiers, \n• numbers, \n• operators and \n• punctuations symbols \nare possible tokens to be identified. \nPattern \nPattern describes a rule that must be matched by sequence of characters \n(lexemes) to form a token. It can be defined by regular expressions or grammar \nrules. \nLexeme \nLexeme is a sequence of characters that matches the pattern for a token i.e., \ninstance of a \ntoken. \n(eg.) c=a+b*5;","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":16,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_16_1763525937720","subject":"cd"}}],["81b47522-cabc-4dd8-b3fb-4ae7041715f0",{"pageContent":"Lexemes and tokens \nLexemes Tokens \nc identifier \n= assignment symbol \na identifier \n+ + (addition symbol) \nb identifier \n* * (multiplication symbol) \n5 5 (number) \nThe sequence of tokens produced by lexical analyzer helps the parser in \nanalyzing the syntax of programming languages. \nRole of Lexical Analyzer \n                         \n \nLexical analyzer performs the following tasks: \n• Reads the source program, scans the input characters, group them into \nlexemes and produce the token as output. \n• Enters the identified token into the symbol table.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":17,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_17_1763525937720","subject":"cd"}}],["26275e39-14cf-433c-82ec-144587d1b40c",{"pageContent":"• Strips out white spaces and comments from source program. \n• Correlates error messages with the source program i.e., displays error \nmessage with its occurrence by specifying the line number. \n• Expands the macros if it is found in the source program. \nTasks of lexical analyzer can be divided into two processes: \nScanning: Performs reading of input characters, removal of white spaces and \ncomments. \nLexical Analysis: Produce tokens as the output. \nNeed of Lexical Analyzer \nSimplicity of design of compiler The removal of white spaces and comments \nenables the syntax analyzer for efficient syntactic constructs. \nCompiler efficiency is improved Specialized buffering techniques for reading \ncharacters speed up the compiler process. \nCompiler portability is enhanced \nRunning example:  \nfloat abs_zero_Kelvin = -273;  \nToken (also called word)  \nA string of characters which logically belong together \nfloat, identifier, equal, minus, intnum, semicolon","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":18,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_18_1763525937720","subject":"cd"}}],["b9f8b7af-06ba-4136-8f5f-ad3b879ae8d9",{"pageContent":"Token (also called word)  \nA string of characters which logically belong together \nfloat, identifier, equal, minus, intnum, semicolon \nTokens are treated as terminal symbols of the grammar \nspecifying the source language \n Pattern  \nThe set of strings for which the same token is produced \nThe pattern is said to match each string in the set  \nfloat, l(l+d+_)*, =, -, d+, ; \n Lexeme","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":19,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_19_1763525937720","subject":"cd"}}],["68c42f10-04ec-450b-acc6-d1c50a2a6c38",{"pageContent":"The sequence of characters matched by a pattern to \nform the corresponding token  \n“float”, “abs_zero_Kelvin”, “=”, “-”, “273”, “;” \n \nIssues in Lexical Analysis \nLexical analysis is the process of producing tokens from the source program. It \nhas the following issues: \n• Lookahead \n• Ambiguities \nLookahead \nLookahead is required to decide when one token will end and the next token \nwill begin. The simple example which has lookahead issues are i vs. if, = vs. ==. \nTherefore a way to describe the lexemes of each token is required. \nA way needed to resolve ambiguities \n• Is if it is two variables i and f or if? \n• Is == is two equal signs =, = or ==? \n• arr(5, 4) vs. fn(5, 4) II in Ada (as array reference syntax and function call \nsyntax are similar. \nHence, the number of lookahead to be considered and a way to describe the \nlexemes of each token is also needed. \nRegular expressions are one of the most popular ways of representing tokens. \nAmbiguities","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":20,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_20_1763525937720","subject":"cd"}}],["f4e55178-bf1d-48cf-873b-d71009144c2b",{"pageContent":"lexemes of each token is also needed. \nRegular expressions are one of the most popular ways of representing tokens. \nAmbiguities \nThe lexical analysis programs written with lex accept ambiguous specifications \nand choose the longest match possible at each input point. Lex can handle \nambiguous specifications. When more than one expression can match the \ncurrent input, lex chooses as follows: \n• The longest match is preferred. \n• Among rules which matched the same number of characters, the rule given \nfirst is preferred.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":21,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_21_1763525937720","subject":"cd"}}],["e53429f9-c173-4005-ad48-ed8c7f428993",{"pageContent":"Lexical Errors \n• A character sequence that cannot be scanned into any valid token is a lexical \nerror. \n• Lexical errors are uncommon, but they still must be handled by a scanner. \n• Misspelling of identifiers, keyword, or operators are considered as lexical \nerrors. \nUsually, a lexical error is caused by the appearance of some illegal character, \nmostly at the beginning of a token. \nError Recovery Schemes \n• Panic mode recovery \n• Local correction \n   o Source text is changed around the error point in order to get a correct text. \n   o Analyzer will be restarted with the resultant new text as input. \n• Global correction \n   o It is an enhanced panic mode recovery. \n   o Preferred when local correction fails. \nPanic mode recovery \nIn panic mode recovery, unmatched patterns are deleted from the remaining \ninput, until the lexical analyzer can find a well-formed token at the beginning \nof what input is left.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":22,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_22_1763525937720","subject":"cd"}}],["4c798e96-3ab5-4541-8e4b-1cc01dc6c601",{"pageContent":"input, until the lexical analyzer can find a well-formed token at the beginning \nof what input is left. \n(eg.) For instance the string fi is encountered for the first time in a C program \nin the context: \nfi (a== f(x)) \nA lexical analyzer cannot tell whether f iis a misspelling of the keyword if or an \nundeclared function identifier. \nSince f i is a valid lexeme for the token id, the lexical analyzer will return the \ntoken id to the parser. \nLexical error handling approaches \nLexical errors can be handled by the following actions:","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":23,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_23_1763525937720","subject":"cd"}}],["e046c075-d199-4a41-ace7-c68a4171fff6",{"pageContent":"• Deleting one character from the remaining input. \n• Inserting a missing character into the remaining input. \n• Replacing a character by another character. \n• Transposing two adjacent characters. \n \nLanguages \nSymbol: An abstract entity, not defined  \nExamples: letters and digits  \nString: A finite sequence of juxtaposed symbols  \nabcb, caba are strings over the symbols a,b, and c  \n|w| is the length of the string w, and is the #symbols in it  \n\u000f is the empty string and is of length 0  \nAlphabet: A finite set of symbols  \nLanguage: A set of strings of symbols from some alphabet  \nΦ and {\u000f} are languages  \nThe set of palindromes over {0,1} is an infinite language  \nThe set of strings, {01, 10, 111} over {0,1} is a finite language  \nIf Σ is an alphabet, Σ ∗ is the set of all strings over Σ \n \nExample: A scanner groups input characters into tokens. For example, if the \ninput is \nx = x*(b+1); \nthen the scanner generates the following sequence of tokens: \nid(1) \n= \nid(1) \n* \n( \nid(2) \n+","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":24,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_24_1763525937720","subject":"cd"}}],["92eaa3f4-35f5-4d8c-9b21-368c7a0ef067",{"pageContent":"input is \nx = x*(b+1); \nthen the scanner generates the following sequence of tokens: \nid(1) \n= \nid(1) \n* \n( \nid(2) \n+ \nnum(1) \n) \n; \nwhere id(1) indicates the identifier with name x (a program variable in this \ncase) and num(1) indicates the integer 1. Each time the parser needs a token, it \nsends a request to the scanner. Then, the scanner reads as many characters from \nthe input stream as it is necessary to construct a single token. The scanner may \nreport an error during scanning (eg, when it finds an end-of-file in the middle \nof a string). Otherwise, when a single token is formed, the scanner is suspended \nand returns the token to the parser. The parser will repeatedly call the scanner \nto read all the tokens from the input stream or until an error is detected (such as \na syntax error).","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":25,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_25_1763525937720","subject":"cd"}}],["f54d24b2-867b-49dc-bbf9-45021b10fe7a",{"pageContent":"Tokens are typically represented by numbers. For example, the token * may be \nassigned the number 35. Some tokens require some extra information. For \nexample, an identifier is a token (so it is represented by some number) but it is \nalso associated with a string that holds the identifier name. For example, the \ntoken id(x) is associated with the string, \"x\". Similarly, the token num(1) is \nassociated with the number, 1. \nSpecification of Tokens \n \nTokens  are  specified  by  patterns,  called regular  expressions.  For  example,  the \nregular  expression [a-z][a-zA-Z0-9]* recognizes  all  identifiers  with  at  least \none alphanumeric letter whose first letter is lower-case alphabetic. \nDescribe the languages denoted by the following regular expressions: \n1. a(a|b)*a \n2. ((ε|a)b*)* \n3. (a|b)*a(a|b)(a|b) \n4. a*ba*ba*ba* \n5. (aa|bb)*((ab|ba)(aa|bb)*(ab|ba)(aa|bb)*)* \nAnswer \n1. String of a's and b's that start and end with a. \n2. String of a's and b's.","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":26,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_26_1763525937720","subject":"cd"}}],["5b9613ce-bcf0-415c-9ff0-b68f0a95ac93",{"pageContent":"4. a*ba*ba*ba* \n5. (aa|bb)*((ab|ba)(aa|bb)*(ab|ba)(aa|bb)*)* \nAnswer \n1. String of a's and b's that start and end with a. \n2. String of a's and b's. \n3. String of a's and b's that the character third from the last is a. \n4. String of a's and b's that only contains three b. \n5. String of a's and b's that has a even number of a and b. \nMost languages are case sensitive, so keywords can be written only one way, and the \nregular expressions describing their lexeme is very simple. However, some languages, like \nSQL, are case insensitive, so a keyword can be written either in lowercase or in uppercase, \nor in any mixture of cases. Thus, the SQL keyword SELECT can also be written select, \nSelect, or sElEcT, for instance. Show how to write a regular expression for a keyword in a \ncase insensitive language. Illustrate the idea by writing the expression for \"select\" in SQL. \nAnswer \nselect -> [Ss][Ee][Ll][Ee][Cc][Tt] \n \nWrite regular definitions for the following languages:","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":27,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_27_1763525937720","subject":"cd"}}],["8b01565e-4ccb-436c-8b20-31f094b440ac",{"pageContent":"1. All strings of lowercase letters that contain the five vowels in order. \n2. All strings of lowercase letters in which the letters are in ascending lexicographic \norder. \n3. Comments, consisting of a string surrounded by /* and */, without an intervening */, \nunless it is inside double-quotes (\") \n4. All strings of a's and b's that do not contain the substring abb. \n5. All strings of a's and b's that do not contain the subsequence abb. \nAnswer \n1、 \nwant -> other* a (other|a)* e (other|e)* i (other|i)* o (other|o)* u (other|u)* \nother -> [bcdfghjklmnpqrstvwxyz] \n2、 \na* b* ... z* \n3、 \n\\/\\*([^*\"]*|\".*\"|\\*+[^/])*\\*\\/ \n4 \nb*(a+b?)* \n5、 \nb* | b*a+ | b*a+ba* \n \nWrite character classes for the following sets of characters: \n1. The first ten letters (up to \"j\") in either upper or lower case. \n2. The lowercase consonants. \n3. The \"digits\" in a hexadecimal number (choose either upper or lower case for the \n\"digits\" above 9).","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":28,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_28_1763525937720","subject":"cd"}}],["b5f7b8fe-64be-4dd2-ba3e-dd9ea4421978",{"pageContent":"2. The lowercase consonants. \n3. The \"digits\" in a hexadecimal number (choose either upper or lower case for the \n\"digits\" above 9). \n4. The characters that can appear at the end of alegitimate English sentence (e.g. , \nexclamation point) . \nAnswer \n1. [A-Ja-j] \n2. [bcdfghjklmnpqrstvwxzy] \n3. [0-9a-f] \n4. [.?!]","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":29,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_29_1763525937720","subject":"cd"}}],["d1dad622-dd6f-41fc-bfc4-6d78b27d02eb",{"pageContent":"Note that these regular expressions give all of the following symbols (operator characters) a \nspecial meaning: \n\\ \" . ^ $ [ ] * + ? { } | / \nTheir special meaning must be turned off if they are needed to represent themselves in a \ncharacter string. We can do so by quoting the character within a string of length one or more; \ne.g., the regular expression \"**\" matches the string ** . W e can also get the literal meaning of \nan operator character by preceding it by a backslash. Thus, the regular expression \\*\\* also \nmatches the string **. Write a regular expression that matches the string \"\\. \nAnswer \n\\\"\\\\ \n \nThe operator ^ matches the left end of a line, and $ matches the right end of a line. The \noperator ^ is also used to introduce complemented character classes, but the context always \nmakes it clear which meaning is intended. For example, ^[^aeiou]*$ matches any complete \nline that does not contain a lowercase vowel. \n1. How do you tell which meaning of ^ is intended?","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":30,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_30_1763525937720","subject":"cd"}}],["dd92a945-5cc0-4de7-968e-9108a5cb237d",{"pageContent":"line that does not contain a lowercase vowel. \n1. How do you tell which meaning of ^ is intended? \nif ^ is in a pair of brakets, and it is the first letter, it means complemented classes, or it means \nthe left end of a line. \n \nRecognition of Tokens \n \nConstruct transition diagram for the following  \n1. who, when, what, why, whom \n2. arithmetic operators \n \n \nwho, when, what, why, whom","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":31,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_31_1763525937720","subject":"cd"}}],["00a058f1-ae48-4eac-ad3c-5a4e3f00bbee",{"pageContent":"Arithmetic operators \n \n \n       \n \n   \n \n \n  \n \n \nstart \n0 \n2 \nreturn (who,”who”) \nreturn \n(whom,”whom”) \nw \no \nother \n4 \n8 \n1 \nh \n7 \ne \nn \n9 \n1\n0 \n* \n3 \na \nt \n6 \ny \n5 \nm \nreturn (why,”why”) \nreturn (when,”when”) \nreturn (what,”what”) \n0 \n1 \n+ \n2 \n3 \n5 \n% \n* \n- \n4 \n/ \nreturn (arithop, ‘+’) \nreturn (arithop, ‘-’) \nreturn (arithop, ‘*’) \nreturn (arithop, ‘%’) \nreturn (arithop, ‘/’)","metadata":{"filename":"1763525936903-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:18:57.720Z","chunkIndex":32,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763525936903-CD-Unit-1_notes.pdf","id":"cd_1763525936903-CD-Unit-1_notes.pdf_chunk_32_1763525937720","subject":"cd"}}],["7d9d1a2f-d17f-4df4-911d-b1ee58c49c65",{"pageContent":"1. Introduction \n \n                          Compiler  is  a  translator  program  that  translates  a  program  written  in \n(HLL)  the  source  program  and  translates  it  into  an  equivalent  program  in  (MLL)  the \ntarget  program.  As  an  important  part of  a  compiler  is  error showing  to the  programmer. \nExecuting  a  program  written  in  HLL  programming  language  is  basically  of  two  parts. \nThe  source  program  must  first  be  compiled  translated  into  an  object  program.  Then  the \nresults object program is loaded into a memory executed. \n \nWho developed the first compiler for a computer programming language? \nThe  first  compiler  was  written  by Grace  Hopper, in  1952,  for the  A-0  System  language. \nThe term compiler was coined by Hopper. The A-0 functioned more as a loader or linker \nthan the  modern notion of a compiler. The FORTRAN team  led by John Backus at IBM","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":0,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_0_1763526066462","subject":"cd"}}],["8ae39e2b-3016-414f-8b80-506360538532",{"pageContent":"than the  modern notion of a compiler. The FORTRAN team  led by John Backus at IBM \nis generally credited as having introduced the first complete compiler in 1957. \n \nLanguage Processing System \n \n                 Source program  \n                           \n                                                                       \nExpands macros \n   \n \n                                       Modified source program \n \n \n \n \n                                      Target assembly program \n \n \nPreprocessor  \nCompiler \nAssembler","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":1,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_1_1763526066462","subject":"cd"}}],["36c1f647-e800-48d6-bbf4-8edb9dfc2c53",{"pageContent":"Relocatable machine code \n \n                                                                                                            \nLibrary files,  \n                  Relocatable object \nfiles \n \n \nTarget machine code \n \nPre-processor, Assembler, Loader and linker are also known as cousins of compiler. \nCompilers and Interpreters \n \n          Compilers generate machine code, whereas interpreters interpret intermediate code \nInterpreters are easier to write and can provide better error messages (symbol table is still \navailable)  Interpreters  are  at  least  5  times  slower  than  machine  code  generated  by \ncompilers Interpreters also require  much  more  memory than  machine code generated by \ncompilers Examples: Perl, Python, Unix Shell, Java, BASIC, LISP. \n \nThe Structure of a compiler \n \nA  compiler  is  a  huge  program  that  can  consists  of  10,000  to  1,000,000  lines  of  code.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":2,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_2_1763526066462","subject":"cd"}}],["b054d46c-1184-4f93-9f63-9c2b6873fded",{"pageContent":"The Structure of a compiler \n \nA  compiler  is  a  huge  program  that  can  consists  of  10,000  to  1,000,000  lines  of  code. \nSince  compiler  is  a  huge  program  it  is  difficult  to  understand  the  entire  compilation \nprocess. So the process  is divided  into number of modules called as PHASES. There are \ntwo major phases of compiler. \n \n  \n \n \n \n \nAnalysis of the source program \nSynthesis of a machine-language program \nThe structure of compiler consists of two parts: \nLinker/Loader \nCompiler \nAnalysis Synthesis","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":3,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_3_1763526066462","subject":"cd"}}],["06dc5af2-e77c-4fbe-8770-4603ba9dd1c2",{"pageContent":"Analysis part \n•  Analysis  part  breaks  the  source  program  into  constituent  pieces  and  imposes  a \ngrammatical structure on them which further uses this structure to create an intermediate \nrepresentation of the source program. \n• It is also termed as front end of compiler. \n• Information about the source program is collected and stored in a data structure called \nsymbol table. \n                       \nSynthesis part \n• Synthesis part takes the intermediate representation as input and transforms it to the \ntarget program. \n• It is also termed as back end of compiler. \n                           \nThe  design  of  compiler  can  be  decomposed  into several  phases,  each  of  which  converts \none form of source program into another.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":4,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_4_1763526066462","subject":"cd"}}],["5b584560-a2c2-4807-919b-654b08f21454",{"pageContent":"Fig 1.1 Structure of Compiler \nThe phases of compiler are as follows: \n1. Lexical analysis \n2. Syntax analysis \n3. Semantic analysis \n4. Intermediate code generation \n5. Code optimization \n6. Code generation \nAll of the aforementioned phases involve the following tasks: \n• Symbol table management.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":5,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_5_1763526066462","subject":"cd"}}],["e71bd1f3-31b2-4d3c-9629-e4bf46834a74",{"pageContent":"• Error handling. \n \nLexical Analysis \n• Lexical analysis is the first phase of compiler which is also termed as scanning. \n• Source program is scanned to read the stream of characters and those characters are \ngrouped to form a sequence called lexemes which produces token as output. \n• Token: Token  is  a  sequence  of  characters  that  represent  lexical  unit,  which  matches \nwith the pattern, such as keywords, operators, identifiers etc. \n• Lexeme: Lexeme is instance of a token i.e., group of characters forming a token. , \n• Pattern: Pattern describes the rule that the  lexemes of a token takes. It is the  structure \nthat must be matched by strings. \n• Once a token is generated the corresponding entry is made in the symbol table. \nInput: stream of characters \nOutput: Token \nToken Template: <token-name, attribute-value> \n(eg.) c=a+b*5; \n \n \n                                                 Lexemes and tokens \n  \nLexemes Tokens \nc identifier \n= assignment symbol \na identifier","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":6,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_6_1763526066462","subject":"cd"}}],["96732704-8238-4f65-b876-c50165f6f8af",{"pageContent":"Lexemes and tokens \n  \nLexemes Tokens \nc identifier \n= assignment symbol \na identifier \n+ + (addition symbol)","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":7,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_7_1763526066462","subject":"cd"}}],["76a76306-e297-47d1-a2a5-94284cce3965",{"pageContent":"b identifier \n* * (multiplication symbol) \n5 5 (number) \n Hence, <id, 1><=>< id, 2>< +><id, 3 >< * >< 5> \nSyntax Analysis \n• Syntax analysis is the second phase of compiler which is also called as parsing. \n• Parser converts the tokens produced by lexical analyzer  into  a  tree  like  representation \ncalled parse tree. \n• A parse tree describes the syntactic structure of the input. \n               \n•  Syntax  tree  is  a  compressed  representation  of  the  parse  tree  in  which  the  operators \nappear as interior nodes and the operands of the operator are the children of the node for \nthat operator. \nInput: Tokens \nOutput: Syntax tree","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":8,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_8_1763526066462","subject":"cd"}}],["0c72bacc-228d-41ea-80aa-2773872fd5dd",{"pageContent":"Semantic Analysis \n• Semantic analysis is the third phase of compiler. \n• It checks for the semantic consistency. \n• Type information is gathered and stored in symbol table or in syntax tree. \n• Performs type checking. \n                 \nIntermediate Code Generation \n•  Intermediate  code  generation  produces  intermediate  representations  for  the  source \nprogram which are of the following forms: \n     o Postfix notation \n     o Three address code","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":9,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_9_1763526066462","subject":"cd"}}],["63893732-a90c-4e87-a685-3d4986fca075",{"pageContent":"o Syntax tree \nMost commonly used form is the three address code. \n        t\n1\n = inttofloat (5) \n        t\n2\n = id\n3\n* tl \n        t\n3\n = id\n2\n + t\n2\n \n        id\n1\n = t\n3\n \nProperties of intermediate code \n • It should be easy to produce. \n• It should be easy to translate into target program. \nCode Optimization \n• Code  optimization  phase  gets  the  intermediate  code  as  input  and  produces  optimized \nintermediate code as output. \n• It results in faster running machine code. \n• It can be done by reducing the number of lines of code for a program. \n• This phase reduces the redundant code  and  attempts  to  improve  the  intermediate  code \nso that faster-running machine code will result. \n• During the code optimization, the result of the program is not affected. \n• To improve the code generation, the optimization involves \n       o Deduction and removal of dead code (unreachable code). \n       o Calculation of constants in expressions and terms.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":10,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_10_1763526066462","subject":"cd"}}],["2c196ea0-1e29-43cc-8af8-8531e55c9709",{"pageContent":"o Deduction and removal of dead code (unreachable code). \n       o Calculation of constants in expressions and terms. \n       o Collapsing of repeated expression into temporary string. \n       o Loop unrolling. \n       o Moving code outside the loop. \n       o Removal of unwanted temporary variables. \n                   t\n1\n = id\n3\n* 5.0 \n                   id\n1\n = id\n2\n + t\n1\n \nCode Generation","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":11,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_11_1763526066462","subject":"cd"}}],["2deef7bb-fafd-45b9-b0d5-05e118026d51",{"pageContent":"• Code generation is the final phase of a compiler. \n• It gets input from code optimization phase and  produces the target code or object code \nas result. \n•  Intermediate  instructions  are  translated  into  a sequence  of  machine  instructions  that \nperform the same task. \n• The code generation involves \n     o Allocation of register and memory. \n     o Generation of correct references. \n     o Generation of correct data types. \n     o Generation of missing code. \n                LDF R\n2\n, id\n3\n \n                MULF R\n2\n, # 5.0 \n                LDF R\n1\n, id\n2\n \n                ADDF R\n1\n, R\n2\n \n                STF id\n1\n, R\n1\n \n \n Symbol Table Management \n • Symbol table is used to store all the information about identifiers used in the program. \n• It is a data structure containing a record for each identifier, with fields for the attributes \nof the identifier. \n• It allows finding the record for each identifier quickly and to store or retrieve data from \nthat record.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":12,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_12_1763526066462","subject":"cd"}}],["26f7832b-c73c-42f3-8963-20fe1241283a",{"pageContent":"of the identifier. \n• It allows finding the record for each identifier quickly and to store or retrieve data from \nthat record. \n• Whenever an identifier is detected in any of the phases, it is stored in the symbol table. \nExample \n int a, b; float c; char z;     \nSymbol name Type Address \na Int 1000","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":13,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_13_1763526066462","subject":"cd"}}],["c8c955b8-e3de-4eba-90f6-626b37cb9475",{"pageContent":"b Int 1002 \nc Float 1004 \nz char 1008 \nExample \nextern double test (double x); \n   double sample (int count) \n{ \n   double sum= 0.0; \n     for (int i = 1; i < = count; i++) \n       sum+= test((double) i); \n       return sum; \n   } \n Symbol name \nType Scope \ntest function, double extern \nx double function parameter \nsample function, double global \ncount int function parameter \nsum double block local \ni int for-loop statement \n   \n \n\n \n \n                             \n \nError Handling","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":14,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_14_1763526066462","subject":"cd"}}],["7c9d936a-aac1-469f-9b1b-5f6e9b0f514c",{"pageContent":"Error Handling \n\n \n \n• Each phase can encounter errors. After detecting an error, a phase must handle the error \nso that compilation can proceed. \n• In lexical analysis, errors occur in separation of tokens. \n• In syntax analysis, errors occur during construction of syntax tree. \n• In semantic analysis, errors may occur at the following cases: \n(i)  When  the  compiler  detects  constructs  that  have  right  syntactic  structure  but  no \nmeaning \n(ii) During type conversion. \n• In code optimization, errors occur when the result is affected by the optimization. In \ncode generation, it shows error when code is missing etc. \nFigure  illustrates  the  translation  of  source  code  through  each  phase,  considering  the \nstatement \n    c =a+ b * 5.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":15,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_15_1763526066462","subject":"cd"}}],["92159b28-c49f-4bef-bbf2-8c8d02b1f722",{"pageContent":"Lexical Analysis \nLexical analysis is the process of converting a sequence of characters from \nsource program into a sequence of tokens. \nA program which performs lexical analysis is termed as a lexical analyzer \n(lexer), tokenizer or scanner. \nLexical analysis consists of two stages of processing which are as follows: \n• Scanning \n• Tokenization \nToken, Pattern and Lexeme \nToken \nToken is a valid sequence of characters which are given by lexeme. In a \nprogramming language, \n• keywords, \n• constant, \n• identifiers, \n• numbers, \n• operators and \n• punctuations symbols \nare possible tokens to be identified. \nPattern \nPattern describes a rule that must be matched by sequence of characters \n(lexemes) to form a token. It can be defined by regular expressions or grammar \nrules. \nLexeme \nLexeme is a sequence of characters that matches the pattern for a token i.e., \ninstance of a \ntoken. \n(eg.) c=a+b*5;","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":16,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_16_1763526066462","subject":"cd"}}],["e35a0472-5d5d-4fed-8815-4b710ad1e8fd",{"pageContent":"Lexemes and tokens \nLexemes Tokens \nc identifier \n= assignment symbol \na identifier \n+ + (addition symbol) \nb identifier \n* * (multiplication symbol) \n5 5 (number) \nThe sequence of tokens produced by lexical analyzer helps the parser in \nanalyzing the syntax of programming languages. \nRole of Lexical Analyzer \n                         \n \nLexical analyzer performs the following tasks: \n• Reads the source program, scans the input characters, group them into \nlexemes and produce the token as output. \n• Enters the identified token into the symbol table.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":17,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_17_1763526066462","subject":"cd"}}],["bd7df8a6-44ff-4855-94d9-96b38aaff229",{"pageContent":"• Strips out white spaces and comments from source program. \n• Correlates error messages with the source program i.e., displays error \nmessage with its occurrence by specifying the line number. \n• Expands the macros if it is found in the source program. \nTasks of lexical analyzer can be divided into two processes: \nScanning: Performs reading of input characters, removal of white spaces and \ncomments. \nLexical Analysis: Produce tokens as the output. \nNeed of Lexical Analyzer \nSimplicity of design of compiler The removal of white spaces and comments \nenables the syntax analyzer for efficient syntactic constructs. \nCompiler efficiency is improved Specialized buffering techniques for reading \ncharacters speed up the compiler process. \nCompiler portability is enhanced \nRunning example:  \nfloat abs_zero_Kelvin = -273;  \nToken (also called word)  \nA string of characters which logically belong together \nfloat, identifier, equal, minus, intnum, semicolon","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":18,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_18_1763526066462","subject":"cd"}}],["ddecd6d1-33cd-4adc-bd00-03596b97a761",{"pageContent":"Token (also called word)  \nA string of characters which logically belong together \nfloat, identifier, equal, minus, intnum, semicolon \nTokens are treated as terminal symbols of the grammar \nspecifying the source language \n Pattern  \nThe set of strings for which the same token is produced \nThe pattern is said to match each string in the set  \nfloat, l(l+d+_)*, =, -, d+, ; \n Lexeme","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":19,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_19_1763526066462","subject":"cd"}}],["218169a3-9666-4d95-ba2c-61bb46ead8a5",{"pageContent":"The sequence of characters matched by a pattern to \nform the corresponding token  \n“float”, “abs_zero_Kelvin”, “=”, “-”, “273”, “;” \n \nIssues in Lexical Analysis \nLexical analysis is the process of producing tokens from the source program. It \nhas the following issues: \n• Lookahead \n• Ambiguities \nLookahead \nLookahead is required to decide when one token will end and the next token \nwill begin. The simple example which has lookahead issues are i vs. if, = vs. ==. \nTherefore a way to describe the lexemes of each token is required. \nA way needed to resolve ambiguities \n• Is if it is two variables i and f or if? \n• Is == is two equal signs =, = or ==? \n• arr(5, 4) vs. fn(5, 4) II in Ada (as array reference syntax and function call \nsyntax are similar. \nHence, the number of lookahead to be considered and a way to describe the \nlexemes of each token is also needed. \nRegular expressions are one of the most popular ways of representing tokens. \nAmbiguities","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":20,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_20_1763526066462","subject":"cd"}}],["b9f9a4dc-4e29-4cc9-91a6-b99e62124e62",{"pageContent":"lexemes of each token is also needed. \nRegular expressions are one of the most popular ways of representing tokens. \nAmbiguities \nThe lexical analysis programs written with lex accept ambiguous specifications \nand choose the longest match possible at each input point. Lex can handle \nambiguous specifications. When more than one expression can match the \ncurrent input, lex chooses as follows: \n• The longest match is preferred. \n• Among rules which matched the same number of characters, the rule given \nfirst is preferred.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":21,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_21_1763526066462","subject":"cd"}}],["2fd8aa12-7958-4ff0-9698-3538f9b666f1",{"pageContent":"Lexical Errors \n• A character sequence that cannot be scanned into any valid token is a lexical \nerror. \n• Lexical errors are uncommon, but they still must be handled by a scanner. \n• Misspelling of identifiers, keyword, or operators are considered as lexical \nerrors. \nUsually, a lexical error is caused by the appearance of some illegal character, \nmostly at the beginning of a token. \nError Recovery Schemes \n• Panic mode recovery \n• Local correction \n   o Source text is changed around the error point in order to get a correct text. \n   o Analyzer will be restarted with the resultant new text as input. \n• Global correction \n   o It is an enhanced panic mode recovery. \n   o Preferred when local correction fails. \nPanic mode recovery \nIn panic mode recovery, unmatched patterns are deleted from the remaining \ninput, until the lexical analyzer can find a well-formed token at the beginning \nof what input is left.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":22,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_22_1763526066462","subject":"cd"}}],["577ab71a-bfb1-4732-9402-b6938e3d90af",{"pageContent":"input, until the lexical analyzer can find a well-formed token at the beginning \nof what input is left. \n(eg.) For instance the string fi is encountered for the first time in a C program \nin the context: \nfi (a== f(x)) \nA lexical analyzer cannot tell whether f iis a misspelling of the keyword if or an \nundeclared function identifier. \nSince f i is a valid lexeme for the token id, the lexical analyzer will return the \ntoken id to the parser. \nLexical error handling approaches \nLexical errors can be handled by the following actions:","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":23,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_23_1763526066462","subject":"cd"}}],["d97370fc-0e9c-4c37-b3e4-04a34f40c12e",{"pageContent":"• Deleting one character from the remaining input. \n• Inserting a missing character into the remaining input. \n• Replacing a character by another character. \n• Transposing two adjacent characters. \n \nLanguages \nSymbol: An abstract entity, not defined  \nExamples: letters and digits  \nString: A finite sequence of juxtaposed symbols  \nabcb, caba are strings over the symbols a,b, and c  \n|w| is the length of the string w, and is the #symbols in it  \n\u000f is the empty string and is of length 0  \nAlphabet: A finite set of symbols  \nLanguage: A set of strings of symbols from some alphabet  \nΦ and {\u000f} are languages  \nThe set of palindromes over {0,1} is an infinite language  \nThe set of strings, {01, 10, 111} over {0,1} is a finite language  \nIf Σ is an alphabet, Σ ∗ is the set of all strings over Σ \n \nExample: A scanner groups input characters into tokens. For example, if the \ninput is \nx = x*(b+1); \nthen the scanner generates the following sequence of tokens: \nid(1) \n= \nid(1) \n* \n( \nid(2) \n+","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":24,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_24_1763526066462","subject":"cd"}}],["ccc94370-4cb0-4967-950f-d7d695aa5cea",{"pageContent":"input is \nx = x*(b+1); \nthen the scanner generates the following sequence of tokens: \nid(1) \n= \nid(1) \n* \n( \nid(2) \n+ \nnum(1) \n) \n; \nwhere id(1) indicates the identifier with name x (a program variable in this \ncase) and num(1) indicates the integer 1. Each time the parser needs a token, it \nsends a request to the scanner. Then, the scanner reads as many characters from \nthe input stream as it is necessary to construct a single token. The scanner may \nreport an error during scanning (eg, when it finds an end-of-file in the middle \nof a string). Otherwise, when a single token is formed, the scanner is suspended \nand returns the token to the parser. The parser will repeatedly call the scanner \nto read all the tokens from the input stream or until an error is detected (such as \na syntax error).","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":25,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_25_1763526066462","subject":"cd"}}],["88fc6c99-c1a9-4471-800c-fbb3eb34f972",{"pageContent":"Tokens are typically represented by numbers. For example, the token * may be \nassigned the number 35. Some tokens require some extra information. For \nexample, an identifier is a token (so it is represented by some number) but it is \nalso associated with a string that holds the identifier name. For example, the \ntoken id(x) is associated with the string, \"x\". Similarly, the token num(1) is \nassociated with the number, 1. \nSpecification of Tokens \n \nTokens  are  specified  by  patterns,  called regular  expressions.  For  example,  the \nregular  expression [a-z][a-zA-Z0-9]* recognizes  all  identifiers  with  at  least \none alphanumeric letter whose first letter is lower-case alphabetic. \nDescribe the languages denoted by the following regular expressions: \n1. a(a|b)*a \n2. ((ε|a)b*)* \n3. (a|b)*a(a|b)(a|b) \n4. a*ba*ba*ba* \n5. (aa|bb)*((ab|ba)(aa|bb)*(ab|ba)(aa|bb)*)* \nAnswer \n1. String of a's and b's that start and end with a. \n2. String of a's and b's.","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":26,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_26_1763526066462","subject":"cd"}}],["7bd12626-5590-496d-9696-281fdc0f53af",{"pageContent":"4. a*ba*ba*ba* \n5. (aa|bb)*((ab|ba)(aa|bb)*(ab|ba)(aa|bb)*)* \nAnswer \n1. String of a's and b's that start and end with a. \n2. String of a's and b's. \n3. String of a's and b's that the character third from the last is a. \n4. String of a's and b's that only contains three b. \n5. String of a's and b's that has a even number of a and b. \nMost languages are case sensitive, so keywords can be written only one way, and the \nregular expressions describing their lexeme is very simple. However, some languages, like \nSQL, are case insensitive, so a keyword can be written either in lowercase or in uppercase, \nor in any mixture of cases. Thus, the SQL keyword SELECT can also be written select, \nSelect, or sElEcT, for instance. Show how to write a regular expression for a keyword in a \ncase insensitive language. Illustrate the idea by writing the expression for \"select\" in SQL. \nAnswer \nselect -> [Ss][Ee][Ll][Ee][Cc][Tt] \n \nWrite regular definitions for the following languages:","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":27,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_27_1763526066462","subject":"cd"}}],["0d2f5f43-89a6-4e0d-bd42-600d1e1b40ab",{"pageContent":"1. All strings of lowercase letters that contain the five vowels in order. \n2. All strings of lowercase letters in which the letters are in ascending lexicographic \norder. \n3. Comments, consisting of a string surrounded by /* and */, without an intervening */, \nunless it is inside double-quotes (\") \n4. All strings of a's and b's that do not contain the substring abb. \n5. All strings of a's and b's that do not contain the subsequence abb. \nAnswer \n1、 \nwant -> other* a (other|a)* e (other|e)* i (other|i)* o (other|o)* u (other|u)* \nother -> [bcdfghjklmnpqrstvwxyz] \n2、 \na* b* ... z* \n3、 \n\\/\\*([^*\"]*|\".*\"|\\*+[^/])*\\*\\/ \n4 \nb*(a+b?)* \n5、 \nb* | b*a+ | b*a+ba* \n \nWrite character classes for the following sets of characters: \n1. The first ten letters (up to \"j\") in either upper or lower case. \n2. The lowercase consonants. \n3. The \"digits\" in a hexadecimal number (choose either upper or lower case for the \n\"digits\" above 9).","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":28,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_28_1763526066462","subject":"cd"}}],["2da9985a-39ef-4d24-8940-a678ff6d8f4d",{"pageContent":"2. The lowercase consonants. \n3. The \"digits\" in a hexadecimal number (choose either upper or lower case for the \n\"digits\" above 9). \n4. The characters that can appear at the end of alegitimate English sentence (e.g. , \nexclamation point) . \nAnswer \n1. [A-Ja-j] \n2. [bcdfghjklmnpqrstvwxzy] \n3. [0-9a-f] \n4. [.?!]","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":29,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_29_1763526066462","subject":"cd"}}],["fa5fd2ec-2ced-492c-9d56-5661936d267b",{"pageContent":"Note that these regular expressions give all of the following symbols (operator characters) a \nspecial meaning: \n\\ \" . ^ $ [ ] * + ? { } | / \nTheir special meaning must be turned off if they are needed to represent themselves in a \ncharacter string. We can do so by quoting the character within a string of length one or more; \ne.g., the regular expression \"**\" matches the string ** . W e can also get the literal meaning of \nan operator character by preceding it by a backslash. Thus, the regular expression \\*\\* also \nmatches the string **. Write a regular expression that matches the string \"\\. \nAnswer \n\\\"\\\\ \n \nThe operator ^ matches the left end of a line, and $ matches the right end of a line. The \noperator ^ is also used to introduce complemented character classes, but the context always \nmakes it clear which meaning is intended. For example, ^[^aeiou]*$ matches any complete \nline that does not contain a lowercase vowel. \n1. How do you tell which meaning of ^ is intended?","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":30,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_30_1763526066462","subject":"cd"}}],["a1f7ea3d-b7c5-4a61-b799-8c2b97e1529e",{"pageContent":"line that does not contain a lowercase vowel. \n1. How do you tell which meaning of ^ is intended? \nif ^ is in a pair of brakets, and it is the first letter, it means complemented classes, or it means \nthe left end of a line. \n \nRecognition of Tokens \n \nConstruct transition diagram for the following  \n1. who, when, what, why, whom \n2. arithmetic operators \n \n \nwho, when, what, why, whom","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":31,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_31_1763526066462","subject":"cd"}}],["8effc689-c0e3-43e0-bed7-c8483acfb3df",{"pageContent":"Arithmetic operators \n \n \n       \n \n   \n \n \n  \n \n \nstart \n0 \n2 \nreturn (who,”who”) \nreturn \n(whom,”whom”) \nw \no \nother \n4 \n8 \n1 \nh \n7 \ne \nn \n9 \n1\n0 \n* \n3 \na \nt \n6 \ny \n5 \nm \nreturn (why,”why”) \nreturn (when,”when”) \nreturn (what,”what”) \n0 \n1 \n+ \n2 \n3 \n5 \n% \n* \n- \n4 \n/ \nreturn (arithop, ‘+’) \nreturn (arithop, ‘-’) \nreturn (arithop, ‘*’) \nreturn (arithop, ‘%’) \nreturn (arithop, ‘/’)","metadata":{"filename":"1763526065645-CD-Unit-1_notes.pdf","uploadDate":"2025-11-19T04:21:06.462Z","chunkIndex":32,"totalChunks":33,"filepath":"C:\\Users\\14-5-2022\\Desktop\\genai\\backend\\uploads\\cd\\1763526065645-CD-Unit-1_notes.pdf","id":"cd_1763526065645-CD-Unit-1_notes.pdf_chunk_32_1763526066462","subject":"cd"}}]],{"0":"093cb33c-7a89-4856-a0ef-d30f587cebaa","1":"732c9f95-4b1b-4e0d-ab17-7aa96aa76eca","2":"c67c8062-bf50-4342-860f-c077c4610dc4","3":"6b541d03-96ce-4323-b239-b957238112d7","4":"705614a0-64b2-4ecb-a0bc-07c162913aac","5":"ce564e97-0e9a-4bd5-953a-cc13030e597f","6":"12892a69-5667-4a8a-b4d0-fc3d908c32a3","7":"1635e15f-1f60-4d1f-a2d7-3c04901c734d","8":"e698b6f2-d56f-4d13-8c21-357e699cd3d3","9":"e2f6cf92-47e5-4333-83ea-8ca41a3d48f7","10":"060883cd-9f05-4a36-8f44-d333144a1dea","11":"0e814c06-739f-4c4e-b00a-c0e07df60eb7","12":"7e662148-b79b-47b7-bc41-c1ec5b2ab6e0","13":"f84bceb2-a27f-4222-94b4-1e2cbb86cea8","14":"4f1108ce-54ab-40e5-a73a-30814498b58c","15":"71ef6205-fcd8-43b6-85ea-145777e3cfb0","16":"8d421b0b-b444-48ba-8a80-68b0c31fdead","17":"81b47522-cabc-4dd8-b3fb-4ae7041715f0","18":"26275e39-14cf-433c-82ec-144587d1b40c","19":"b9f8b7af-06ba-4136-8f5f-ad3b879ae8d9","20":"68c42f10-04ec-450b-acc6-d1c50a2a6c38","21":"f4e55178-bf1d-48cf-873b-d71009144c2b","22":"e53429f9-c173-4005-ad48-ed8c7f428993","23":"4c798e96-3ab5-4541-8e4b-1cc01dc6c601","24":"e046c075-d199-4a41-ace7-c68a4171fff6","25":"92eaa3f4-35f5-4d8c-9b21-368c7a0ef067","26":"f54d24b2-867b-49dc-bbf9-45021b10fe7a","27":"5b9613ce-bcf0-415c-9ff0-b68f0a95ac93","28":"8b01565e-4ccb-436c-8b20-31f094b440ac","29":"b5f7b8fe-64be-4dd2-ba3e-dd9ea4421978","30":"d1dad622-dd6f-41fc-bfc4-6d78b27d02eb","31":"dd92a945-5cc0-4de7-968e-9108a5cb237d","32":"00a058f1-ae48-4eac-ad3c-5a4e3f00bbee","33":"7d9d1a2f-d17f-4df4-911d-b1ee58c49c65","34":"8ae39e2b-3016-414f-8b80-506360538532","35":"36c1f647-e800-48d6-bbf4-8edb9dfc2c53","36":"b054d46c-1184-4f93-9f63-9c2b6873fded","37":"06dc5af2-e77c-4fbe-8770-4603ba9dd1c2","38":"5b584560-a2c2-4807-919b-654b08f21454","39":"e71bd1f3-31b2-4d3c-9629-e4bf46834a74","40":"96732704-8238-4f65-b876-c50165f6f8af","41":"76a76306-e297-47d1-a2a5-94284cce3965","42":"0c72bacc-228d-41ea-80aa-2773872fd5dd","43":"63893732-a90c-4e87-a685-3d4986fca075","44":"2c196ea0-1e29-43cc-8af8-8531e55c9709","45":"2deef7bb-fafd-45b9-b0d5-05e118026d51","46":"26f7832b-c73c-42f3-8963-20fe1241283a","47":"c8c955b8-e3de-4eba-90f6-626b37cb9475","48":"7c9d936a-aac1-469f-9b1b-5f6e9b0f514c","49":"92159b28-c49f-4bef-bbf2-8c8d02b1f722","50":"e35a0472-5d5d-4fed-8815-4b710ad1e8fd","51":"bd7df8a6-44ff-4855-94d9-96b38aaff229","52":"ddecd6d1-33cd-4adc-bd00-03596b97a761","53":"218169a3-9666-4d95-ba2c-61bb46ead8a5","54":"b9f9a4dc-4e29-4cc9-91a6-b99e62124e62","55":"2fd8aa12-7958-4ff0-9698-3538f9b666f1","56":"577ab71a-bfb1-4732-9402-b6938e3d90af","57":"d97370fc-0e9c-4c37-b3e4-04a34f40c12e","58":"ccc94370-4cb0-4967-950f-d7d695aa5cea","59":"88fc6c99-c1a9-4471-800c-fbb3eb34f972","60":"7bd12626-5590-496d-9696-281fdc0f53af","61":"0d2f5f43-89a6-4e0d-bd42-600d1e1b40ab","62":"2da9985a-39ef-4d24-8940-a678ff6d8f4d","63":"fa5fd2ec-2ced-492c-9d56-5661936d267b","64":"a1f7ea3d-b7c5-4a61-b799-8c2b97e1529e","65":"8effc689-c0e3-43e0-bed7-c8483acfb3df"}]